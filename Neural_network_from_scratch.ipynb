{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks from scratch in python - Learn handwritten numbers \" MNIST database \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow is only used to load the handwritten numbers dataset and has nothing to do with building or testing the neural network.\n",
    "# matplotlib same thing. It is used only to show the first image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install numpy\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf  # Library for machine learning and neural networks\n",
    "from tensorflow import keras  # Sub-library for building neural networks\n",
    "import numpy as np  # Library for numerical computations\n",
    "import matplotlib.pyplot as plt  # Library for plotting graphs and images\n",
    "from Draw_Numbers import HandwritingRecognition # draw_image : This is not a library, but rather a Python file attached to this notebook in studypool.\n",
    "                                                #              Place it in the same folder with this notebook and run it to be imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset (handwritten digits)\n",
    "data = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = data.load_data()\n",
    "\n",
    "# Normalize pixel values to 0-1 range\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to display a sample image\n",
    "def generate_image(x): \n",
    "    plt.imshow(train_images[x], cmap='gray', vmin=0, vmax=1)  # Show the image\n",
    "    plt.axis('off')  # Turn off the axes\n",
    "    plt.show()  # Display the image\n",
    "\n",
    "# Show the first image in the dataset\n",
    "generate_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images to a 1D array (flatten)\n",
    "train_images = train_images.reshape(60000, -1)\n",
    "test_images = test_images.reshape(10000, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the data\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Define classes for building a neural network\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Dense layer (fully connected layer)\n",
    "class layer_Dense:\n",
    "    def __init__(self, n_input, n_neurons):\n",
    "        np.random.seed(0) # Set a random seed for reproducibility\n",
    "        self.weights = 0.1 * np.random.randn(n_neurons, n_input) # Initialize weights with small random values\n",
    "        self.biases = np.zeros((n_neurons, 1)) # Initialize biases to zero\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.dot(self.weights, inputs) + self.biases  # Calculate output using matrix multiplication\n",
    "\n",
    "    # This method is responsible for calculating the gradients (derivatives) of the loss function with respect to the weights and biases of the layer.\n",
    "    def backward(self, dvalues): \n",
    "        self.dweights = np.dot(dvalues, self.inputs.T)\n",
    "        self.dbiases = np.sum(dvalues, axis=1, keepdims=True)\n",
    "        self.dZ = np.dot(self.weights.T, dvalues) # Calculates the error signals (dZ) to be passed back to the previous layer in the network.\n",
    "\n",
    "    def update_weights(self, learning_rate):          # This method updates the weights and biases of the layer based on the calculated gradients\n",
    "                                                      #                              and the learning rate.\n",
    "        self.weights -= learning_rate * self.dweights\n",
    "        self.biases -= learning_rate * self.dbiases\n",
    "\n",
    "# Leaky ReLU activation function\n",
    "class Activation_Leaky_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0.01 * inputs, inputs) # g(Z) = Z*0.01 if Z<0 / Z if Z>0\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "        self.gPrim = np.where(self.inputs > 0, 1, 0.01) # g'(Z) = 0.01 if Z<0 / 1 if Z>0\n",
    "        self.dvalues = dvalues * self.gPrim\n",
    "\n",
    "# Softmax activation function\n",
    "class Activation_softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=0, keepdims=True)) # Exponential e^x\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=0, keepdims=True) # Normlize\n",
    "        self.output = probabilities\n",
    "    \n",
    "    # derivative of softmax\n",
    "    def backward(self, dvalues, y_true):\n",
    "        dvalues.T[range(len(dvalues.T)), y_true] -= 1\n",
    "        self.dZ3 = dvalues\n",
    "\n",
    "class loss:\n",
    "    def calculate(self, output, labels):\n",
    "        sample_losses = self.forward(output, labels) # sample_losses = negative_log\n",
    "        data_loss = np.mean(sample_losses) # Calculate the average loss of all outputs          \n",
    "        return data_loss                                \n",
    "                                                         \n",
    "class loss_All_outputs(loss): # Calculate the loss of all outputs separately         \n",
    "    def forward(self, y_pred, y_true): \n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7) # 0 < y_pred < 1 \n",
    "        correct_confidences = y_pred_clipped.T[range(len(y_pred.T)), y_true]\n",
    "        negative_log = -np.log(correct_confidences)\n",
    "        return negative_log\n",
    "\n",
    "class Accuracy: # Calculating the accuracy of a neural network \" % \"\n",
    "    def calculate_accuracy(self, output, labels):\n",
    "        predictions = np.argmax(output, axis=0)\n",
    "        accuracy = np.mean(predictions == labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = layer_Dense(784, 128)  # First dense layer with 784 inputs and 128 neurons\n",
    "activation1 = Activation_Leaky_ReLU()  # Leaky ReLU activation after the first layer\n",
    "\n",
    "layer2 = layer_Dense(128, 128)  # Second dense layer with 128 neurons\n",
    "activation2 = Activation_Leaky_ReLU()  # Leaky ReLU activation after the second layer\n",
    "\n",
    "layer3 = layer_Dense(128, 10)  # Output layer with 10 neurons (one for each digit class)\n",
    "activation3 = Activation_softmax()  # Softmax activation for probability distribution\n",
    "\n",
    "loss_function = loss_All_outputs()  # Loss function (categorical cross-entropy)\n",
    "\n",
    "Acc = Accuracy()  # Accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.12168472941067646, Accuracy: 96.10666666666667%\n",
      "Epoch 2/10, Loss: 0.08863813505977866, Accuracy: 97.17833333333333%\n",
      "Epoch 3/10, Loss: 0.05997170799426557, Accuracy: 98.07333333333334%\n",
      "Epoch 4/10, Loss: 0.11106471828355244, Accuracy: 96.56333333333333%\n",
      "Epoch 5/10, Loss: 0.051351164940773845, Accuracy: 98.26833333333333%\n",
      "Epoch 6/10, Loss: 0.04378385814285696, Accuracy: 98.61999999999999%\n",
      "Epoch 7/10, Loss: 0.051508246453971854, Accuracy: 98.45666666666666%\n",
      "Epoch 8/10, Loss: 0.045576104787855114, Accuracy: 98.5%\n",
      "Epoch 9/10, Loss: 0.030020671508613955, Accuracy: 99.02833333333334%\n",
      "Epoch 10/10, Loss: 0.02935192207314951, Accuracy: 99.04666666666667%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters (settings for training)\n",
    "learning_rate = 0.01  # How much to adjust weights during training\n",
    "batch_size = 32  # Number of images processed in each step\n",
    "epochs = 10  # Number of times to loop through the entire dataset\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Train the neural network using mini-batch gradient descent\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Mini-Batch Gradient Descent\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(train_images), batch_size):\n",
    "        batch_images = train_images[i:i + batch_size]\n",
    "        batch_labels = train_labels[i:i + batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        layer1.forward(batch_images.T)\n",
    "        activation1.forward(layer1.output)\n",
    "\n",
    "        layer2.forward(activation1.output)\n",
    "        activation2.forward(layer2.output)\n",
    "\n",
    "        layer3.forward(activation2.output)\n",
    "        activation3.forward(layer3.output)\n",
    "\n",
    "        # Backpropagation\n",
    "        activation3.backward(activation3.output, batch_labels) # <= dZ3\n",
    "        layer3.backward(activation3.dZ3)               # W3 / B3\n",
    "\n",
    "        activation2.backward(layer3.dZ) # <= dZ2\n",
    "        layer2.backward(activation2.dvalues)           # W2 / B2\n",
    "\n",
    "        activation1.backward(layer2.dZ) # <= dZ1\n",
    "        layer1.backward(activation1.dvalues)           # W1 / B1\n",
    "\n",
    "        # Update weights and biases\n",
    "        layer1.update_weights(learning_rate)\n",
    "        layer2.update_weights(learning_rate)\n",
    "        layer3.update_weights(learning_rate)\n",
    "\n",
    "    # Calculate accuracy after each training session\n",
    "    layer1.forward(train_images.T)\n",
    "    activation1.forward(layer1.output)\n",
    "\n",
    "    layer2.forward(activation1.output)\n",
    "    activation2.forward(layer2.output)\n",
    "\n",
    "    layer3.forward(activation2.output)\n",
    "    activation3.forward(layer3.output)\n",
    "\n",
    "    loss = loss_function.calculate(activation3.output, train_labels)\n",
    "\n",
    "    accuracy = Acc.calculate_accuracy(activation3.output, train_labels)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss}, Accuracy: {accuracy * 100}%\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.10596625953065728, Accuracy: 97.52%\n"
     ]
    }
   ],
   "source": [
    "layer1.forward(test_images.T)\n",
    "activation1.forward(layer1.output)\n",
    "\n",
    "layer2.forward(activation1.output)\n",
    "activation2.forward(layer2.output)\n",
    "\n",
    "layer3.forward(activation2.output)\n",
    "activation3.forward(layer3.output)\n",
    "\n",
    "# ------------------------------------\n",
    "# Evaluate performance on the test\n",
    "# ------------------------------------\n",
    "\n",
    "test_loss = loss_function.calculate(activation3.output, test_labels)\n",
    "\n",
    "test_acc = Acc.calculate_accuracy(activation3.output, test_labels)\n",
    "\n",
    "print(f\"Loss: {test_loss}, Accuracy: {test_acc * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[[2.85590827e-06 2.46914458e-07 4.08576760e-05 4.54212212e-06\n",
      "  1.29603526e-08 2.25726490e-08 6.42835852e-09 5.79778331e-07\n",
      "  9.99944245e-01 6.63090471e-06]]\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# Neural network testing\n",
    "# --------------------------------\n",
    "\n",
    "handwriting_recognition = HandwritingRecognition() \n",
    "\n",
    "handwriting_recognition.draw()\n",
    "\n",
    "matrix_test = handwriting_recognition.image_matrix / 255.0\n",
    "\n",
    "plt.imshow(matrix_test, cmap='gray', vmin=0, vmax=1)\n",
    "plt.axis('off')  \n",
    "plt.show()\n",
    "\n",
    "matrix_test = matrix_test.reshape(-1, 1)\n",
    "\n",
    "layer1.forward(matrix_test)\n",
    "activation1.forward(layer1.output)\n",
    "\n",
    "layer2.forward(activation1.output)\n",
    "activation2.forward(layer2.output)\n",
    "\n",
    "layer3.forward(activation2.output)\n",
    "activation3.forward(layer3.output)\n",
    "\n",
    "print(np.argmax(activation3.output))\n",
    "\n",
    "print(activation3.output.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
